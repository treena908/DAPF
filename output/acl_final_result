


##################baseline##################
roberta-base mlm 
roberta-base
comb acc avg. 0.8740
combo acc std 0.0110
combo acc max 0.8896
comb prec avg. 0.8138
combo prec std 0.0415
combo prec max 0.8696
comb rec avg. 0.8185
combo rec std 0.0306
combo rec max 0.8614
comb f1 avg. 0.8147
combo f1 std 0.0111
combo f1 max 0.8290

##########################
switchprompt
bert-base-uncased_epoch10_optimadamw_pre6_bs16_joint_lr0.5_cvFalse
acc mean 0.59028
acc std 0.11326
acc max 0.75000
f1 mean 0.48654
f1 std 0.18596
acc max 0.75000
f1 max 0.74825

temp [7,4,40]b [47,49,41] adress test
roberta-base+ber
comb acc avg. 0.8495
combo acc std 0.0256
combo acc max 0.8958
comb prec avg. 0.9251
combo prec std 0.0449
combo prec max 1.0000
comb rec avg. 0.7639
combo rec std 0.0556
combo rec max 0.8333
comb f1 avg. 0.8346
combo f1 std 0.0317
combo f1 max 0.8889

roberta-base   +bert 
adrs test mlm     
comb acc avg. 0.8681
combo acc std 0.0098
combo acc max 0.8750
comb prec avg. 0.8998
combo prec std 0.0162
combo prec max 0.9091
comb rec avg. 0.8287
combo rec std 0.0131
combo rec max 0.8333
comb f1 avg. 0.8627
combo f1 std 0.0099
combo f1 max 0.8696

mlm baseline cv combo baselene
roberta-base
comb acc avg. 0.8398
combo acc std 0.0737
combo acc max 0.8863
comb prec avg. 0.8526
combo prec std 0.0108
combo prec max 0.8621
comb rec avg. 0.6315
combo rec std 0.2588
combo rec max 0.7921
comb f1 avg. 0.6869
combo f1 std 0.2326
combo f1 max 0.8247
9


cv combo bert+roberta
[47, 49, 41]
bert-base-uncased
comb acc avg. 0.8510
combo acc std 0.0185
combo acc max 0.8729
comb prec avg. 0.7669
comb rec avg. 0.8130
combo rec std 0.0325
combo rec max 0.8812
comb f1 avg. 0.7873
combo f1 std 0.0163
combo f1 max 0.8116
cv combo
[47, 49, 41]
ert-base-uncased
comb acc avg. 0.8528
combo acc std 0.0142
combo acc max 0.8629
comb prec avg. 0.7716
combo prec std 0.0415
combo prec max 0.8191
comb rec avg. 0.8086
combo rec std 0.0327
combo rec max 0.8317
comb f1 avg. 0.7881
combo f1 std 0.0136
combo f1 max 0.8038

cv combo
[47, 49, 41]
roberta-base
comb acc avg. 0.7269
combo acc std 0.0356
combo acc max 0.7759
comb prec avg. 0.5739
combo prec std 0.0487
combo prec max 0.6417
comb rec avg. 0.7921
combo rec std 0.0214
combo rec max 0.8119
comb f1 avg. 0.6636
combo f1 std 0.0241
combo f1 max 0.6968


baseline adress test
bert-base-uncased

comb acc avg. 0.8681
combo acc std 0.0098
combo acc max 0.8750
comb prec avg. 0.8381
combo prec std 0.0339
combo prec max 0.8750
comb rec avg. 0.9167
combo rec std 0.0340
combo rec max 0.9583
comb f1 avg. 0.8743
combo f1 std 0.0050
combo f1 max 0.8800

baseline adress test
roberta-base
comb acc avg. 0.8611
combo acc std 0.0098
combo acc max 0.8750
comb prec avg. 0.8945
combo prec std 0.0177
combo prec max 0.9091
comb rec avg. 0.8194
combo rec std 0.0196
combo rec max 0.8333
comb f1 avg. 0.8550
comb acc avg. 0.8611
combo acc std 0.0098
combo acc max 0.8750
comb prec avg. 0.8945
combo prec std 0.0177
combo prec max 0.9091
comb rec avg. 0.8194
combo rec std 0.0196
combo rec max 0.8333
comb f1 avg. 0.8550
combo f1 std 0.0106
combo f1 max 0.8696
cvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
baseline cv compo
roberta-base
comb acc avg. 0.8896
combo acc std 0.0000
combo acc max 0.8896
comb prec avg. 0.8696
combo prec std 0.0000
combo prec max 0.8696
comb rec avg. 0.7921
combo rec std 0.0000
combo rec max 0.7921
comb f1 avg. 0.8290
combo f1 std 0.0000
combo f1 max 0.8290
cv compo
bert-base-uncased
comb acc avg. 0.8172
combo acc std 0.0812
combo acc max 0.8763
comb prec avg. 0.8503
combo prec std 0.0123
combo prec max 0.8621
comb rec avg. 0.5512
combo rec std 0.2848
combo rec max 0.7624
comb f1 avg. 0.6188
combo f1 std 0.2593
combo f1 max 0.8063






###############################################



temp 47,49,41 adress test
bert-base-uncased   
comb acc avg. 0.8750
combo acc std 0.0000
combo acc max 0.8750
comb prec avg. 0.9091
combo prec std 0.0000
combo prec max 0.9091
comb rec avg. 0.8333
combo rec std 0.0000
combo rec max 0.8333
comb f1 avg. 0.8696
combo f1 std 0.0000
combo f1 max 0.8696


[4, 7, 40]          
temp adress test
bert-base-uncased   
comb acc avg. 0.9028
combo acc std 0.0098
combo acc max 0.9167
comb prec avg. 0.9690
combo prec std 0.0220
combo prec max 1.0000
comb rec avg. 0.8333
combo rec std 0.0340
combo rec max 0.8750
comb f1 avg. 0.8952
combo f1 std 0.0128
combo f1 max 0.9130

[4, 7, 40]
temp adress test
roberta-base
comb acc avg. 0.7778
combo acc std 0.0196
combo acc max 0.7917
comb prec avg. 0.8469
combo prec std 0.0958
combo prec max 0.9375
comb rec avg. 0.7083
combo rec std 0.0900
combo rec max 0.8333
comb f1 avg. 0.7604
combo f1 std 0.0079
combo f1 max 0.7692

[47, 49, 41]        
temp adress test
roberta-base
comb acc avg. 0.7986
combo acc std 0.0098
combo acc max 0.8125
comb prec avg. 0.7921
combo prec std 0.0466
combo prec max 0.8571
comb rec avg. 0.8194
combo rec std 0.0520
combo rec max 0.8750
comb f1 avg. 0.8026
combo f1 std 0.0036
combo f1 max 0.8077

test summary
bert-base-uncased_tempmanual40_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint
acc mean 0.86111
acc std 0.00982
acc max 0.87500
f1 mean 0.86024
f1 std 0.00904
acc max 0.87500
f1 max 0.87302
root@example:/data/prompt_ad_code# python postprocess_result.py 
{'acc': [0.8958333333333333, 0.875, 0.8958333333333333], 'f1': [0.8946906537955244, 0.874782608695652, 0.8946906537955244]}
test summary
bert-base-uncased_tempmanual7_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint
acc mean 0.88889
acc std 0.00982
acc max 0.89583
f1 mean 0.88805
f1 std 0.00938
acc max 0.89583
f1 max 0.89469
{'acc': [0.8958333333333333, 0.8541666666666667, 0.875], 'f1': [0.8946906537955244, 0.8541033434650456, 0.875]}
test summary
bert-base-uncased_tempmanual4_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint
acc mean 0.87500
acc std 0.01701
acc max 0.89583
f1 mean 0.87460
f1 std 0.01657
acc max 0.89583
f1 max 0.89469
{'acc': [0.8541666666666666, 0.875, 0.8541666666666667], 'f1': [0.85359477124183, 0.873015873015873, 0.8541033434650456]}
test summary
bert-base-uncased_tempmanual40_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint
acc mean 0.86111
acc std 0.00982
acc max 0.87500
f1 mean 0.86024
f1 std 0.00904
acc max 0.87500
f1 max 0.87302
##################################
{'acc': [0.7916666666666667, 0.7916666666666666, 0.7916666666666666, 0.7916666666666667, 0.7916666666666667], 'f1': [0.7913043478260869, 0.7916666666666666, 0.79166
66666666666, 0.7913043478260869, 0.7913043478260869]}
test summary
roberta-base_tempmanual49_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvFalse_mFalse
acc mean 0.79167
acc std 0.00000
acc max 0.79167
f1 mean 0.79145
f1 std 0.00018
acc max 0.79167
f1 max 0.79167
{'acc': [0.7916666666666666, 0.7916666666666666, 0.7916666666666666, 0.7708333333333334, 0.7708333333333334], 'f1': [0.7883597883597884, 0.7883597883597884, 0.78835
97883597884, 0.7624831309041837, 0.7624831309041837]}
test summary
roberta-base_tempmanual47_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvFalse_mFalse
acc mean 0.78333
acc std 0.01021
acc max 0.79167
f1 mean 0.77801
roberta-base_tempmanual41_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvFalse_mFalse
acc mean 0.77917
acc std 0.01021
acc max 0.79167
f1 mean 0.77612
f1 std 0.01312
acc max 0.79167
f1 max 0.79130

cv#############
{0: {'acc': [0.8875, 0.8999999999999999, 0.5125, 0.9102564102564102, 0.8974358974358974], 'f1': [0.8447829836159817, 0.8755555555555556, 0.4998187749184487, 0.87623
61402457297, 0.862857142857143], 'fold': [0, 1, 2, 3, 4]}, 1: {'acc': [0.925, 0.9, 0.5375, 0.9102564102564102, 0.8644688644688645], 'f1': [0.8942420681551116, 0.861
1111111111112, 0.5099971838918614, 0.8762361402457297, 0.8564593301435407], 'fold': [0, 1, 2, 3, 4]}, 2: {'acc': [0.9375, 0.8875, 0.5625, 0.8852564102564102, 0.8516
483516483516], 'f1': [0.9111111111111112, 0.8589894242068156, 0.5555555555555555, 0.857487922705314, 0.8399999999999999], 'fold': [0, 1, 2, 3, 4]}}
{'acc': [0.8215384615384614, 0.8274450549450549, 0.8248809523809524], 'acc_std': [0.15468885123663542, 0.1463405653151916, 0.13402212411455433], 'f1': [0.7918501194
385718, 0.7996091667094709, 0.8046288027157592], 'f1_std': [0.14646077441432637, 0.14540743443755347, 0.12678820906094976]}
cv summary
bert-base-uncased_tempmanual49_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvTrue_mFalse
acc mean 0.82462
acc std 0.14502
f1 mean 0.79870
f1 std 0.13955
{0: {'acc': [0.9, 0.8625, 0.5499999999999999, 0.898076923076923, 0.8608058608058609], 'f1': [0.8611111111111112, 0.8263888888888891, 0.52, 0.8742770167427701, 0.828
5714285714285], 'fold': [0, 1, 2, 3, 4]}, 1: {'acc': [0.975, 0.925, 0.55, 0.8474358974358974, 0.9120879120879121], 'f1': [0.9633699633699633, 0.9093929326487467, 0.
5433127944907575, 0.8218599033816425, 0.8942420681551115], 'fold': [0, 1, 2, 3, 4]}, 2: {'acc': [0.9375, 0.9625, 0.575, 0.8621794871794872, 0.8608058608058609], 'f1
': [0.9111111111111112, 0.945635759589248, 0.55810147299509, 0.8800813008130082, 0.8285714285714285], 'fold': [0, 1, 2, 3, 4]}}
{'acc': [0.8142765567765569, 0.8419047619047619, 0.8395970695970696], 'acc_std': [0.13319428304668876, 0.15151489633056053, 0.13831955879836363], 'f1': [0.782069689
0628398, 0.8264355324092442, 0.8247002146159771], 'f1_std': [0.1323305428488272, 0.14860021267437462, 0.1387437848054947]}
cv summary
bert-base-uncased_tempmanual47_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvTrue_mFalse
acc mean 0.83193
acc std 0.14101
f1 mean 0.81107
f1 std 0.13989
{0: {'acc': [0.9125, 0.9125000000000001, 0.55, 0.8743589743589744, 0.8846153846153846], 'f1': [0.877586709414165, 0.9073788206236493, 0.5485636114911081, 0.88355263
15789474, 0.8465473145780051], 'fold': [0, 1, 2, 3, 4]}, 1: {'acc': [0.85, 0.9375, 0.55, 0.8852564102564102, 0.8736263736263736], 'f1': [0.8632367307066102, 0.91111
11111111112, 0.5433127944907575, 0.857487922705314, 0.8447829836159816], 'fold': [0, 1, 2, 3, 4]}, 2: {'acc': [0.925, 0.9125, 0.55, 0.875], 'f1': [0.925, 0.87758670
9414165, 0.5341614906832298, 0.8984509466437177], 'fold': [0, 1, 2, 3]}}
{'acc': [0.8267948717948718, 0.819276556776557, 0.815625], 'acc_std': [0.13922046876002822, 0.13765015087342303, 0.15445847945321745], 'f1': [0.812725817537175, 0.8
039863085259549, 0.8087997866852781], 'f1_std': [0.13349766188280757, 0.1322602042907473, 0.15945034840483976]}
cv summary
bert-base-uncased_tempmanual41_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvTrue_mFalse
acc mean 0.82057
acc std 0.14378
f1 mean 0.80850
f1 std 0.14174


{0: {'acc': [0.8625, 0.875, 0.5875, 0.6326923076923077, 0.8864468864468864], 'f1': [0.8534798534798536, 0.870330348873109, 0.5588235294117648, 0.6136904761904762, 0
.8611111111111112], 'fold': [0, 1, 2, 3, 4]}, 1: {'acc': [0.5, 0.875, 0.525, 0.9621794871794871, 0.9102564102564102], 'f1': [0.25, 0.8426114835324978, 0.51111111111
11112, 0.9621794871794872, 0.8792756539235412], 'fold': [0, 1, 2, 3, 4]}, 2: {'acc': [0.8375, 0.675, 0.5, 0.8615384615384616, 0.5], 'f1': [0.7803435651929034, 0.677
1130104463439, 0.25, 0.8659526127880558, 0.25925925925925924], 'fold': [0, 1, 2, 3, 4]}}
{'acc': [0.7688278388278389, 0.7544871794871795, 0.6748076923076923], 'acc_std': [0.1306092721983936, 0.19967552574578093, 0.15649451282514254], 'f1': [0.7514870638
13263, 0.6890355471493275, 0.5665336895373124], 'f1_std': [0.13612554818424913, 0.2678782540770557, 0.2616124205216573]}
cv summary
roberta-base_tempmanual49_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvTrue_mFalse
acc mean 0.73271
acc std 0.16226
f1 mean 0.66902
f1 std 0.22187
{0: {'acc': [0.8625, 0.5, 0.5, 0.5794871794871795, 0.8754578754578755], 'f1': [0.8670465337132003, 0.25, 0.25, 0.5079091170549324, 0.8589894242068155], 'fold': [0, 
1, 2, 3, 4]}, 1: {'acc': [0.5, 0.875, 0.575, 0.658974358974359, 0.8406593406593407], 'f1': [0.25, 0.8564593301435407, 0.5738636363636364, 0.6524031007751938, 0.8369
072787677438], 'fold': [0, 1, 2, 3, 4]}, 2: {'acc': [0.5125, 0.5, 0.55, 0.5115384615384616, 0.8754578754578755], 'f1': [0.44341372912801486, 0.25, 0.543312794490757
5, 0.4670967741935484, 0.8589894242068155], 'fold': [0, 1, 2, 3, 4]}}
{'acc': [0.663489010989011, 0.6899267399267399, 0.5898992673992673], 'acc_std': [0.17032310141336895, 0.14643141773114643, 0.14376968452590494], 'f1': [0.5467890149
949897, 0.6339266692100229, 0.5125625444038272], 'f1_std': [0.2748501624939662, 0.22003206439397277, 0.1983657962296509]}
cv summary
roberta-base_tempmanual47_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvTrue_mFalse
acc mean 0.64777
acc std 0.15351
f1 mean 0.56443
f1 std 0.23108
{1: {'acc': [0.6125, 0.8125, 0.5, 0.6961538461538461, 0.5128205128205128], 'f1': [0.6148908857509628, 0.7757976430008623, 0.25, 0.6793478260869565, 0.28750000000000
003], 'fold': [0, 1, 2, 3, 4]}, 2: {'acc': [0.8999999999999999, 0.5, 0.5375, 0.8602564102564103, 0.8882783882783882], 'f1': [0.8755555555555556, 0.25, 0.52254641909
81433, 0.8383561643835615, 0.8755555555555556], 'fold': [0, 1, 2, 3, 4]}}
{'acc': [0.6267948717948718, 0.7372069597069597], 'acc_std': [0.11710550742175861, 0.17922908763244977], 'f1': [0.5215072709677563, 0.6724027389185633], 'f1_std': [
0.21296635166766914, 0.24938470830212406]}
cv summary
roberta-base_tempmanual41_verbmanual_epoch10_optimadamw_stk0_100_domain2_bs16_prlr0.5_joint_tuneTrue_cvTrue_mFalse
acc mean 0.68200
acc std 0.14817
f1 mean 0.59696
f1 std 0.23118

